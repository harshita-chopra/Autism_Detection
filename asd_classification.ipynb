{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autism Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Importing the libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelBinarizer, StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score, KFold\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from pprint import pprint\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the dataset\n",
    "dataset = pd.read_csv('Phenotypic_V1_0b_preprocessed1.csv')\n",
    "\n",
    "# Creating dataset with selected features only\n",
    "my_dataset = dataset.loc[:,['SUB_ID','SEX','HANDEDNESS_CATEGORY','AGE_AT_SCAN','FIQ','VIQ','PIQ','ADOS_TOTAL',\n",
    "                            'ADI_R_SOCIAL_TOTAL_A','ADI_R_VERBAL_TOTAL_BV','ADI_RRB_TOTAL_C','ADI_R_ONSET_TOTAL_D',\n",
    "                            'SUB_IN_SMP','CURRENT_MED_STATUS','DSM_IV_TR']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUB_ID</th>\n",
       "      <th>SEX</th>\n",
       "      <th>HANDEDNESS_CATEGORY</th>\n",
       "      <th>AGE_AT_SCAN</th>\n",
       "      <th>FIQ</th>\n",
       "      <th>VIQ</th>\n",
       "      <th>PIQ</th>\n",
       "      <th>ADOS_TOTAL</th>\n",
       "      <th>ADI_R_SOCIAL_TOTAL_A</th>\n",
       "      <th>ADI_R_VERBAL_TOTAL_BV</th>\n",
       "      <th>ADI_RRB_TOTAL_C</th>\n",
       "      <th>ADI_R_ONSET_TOTAL_D</th>\n",
       "      <th>SUB_IN_SMP</th>\n",
       "      <th>CURRENT_MED_STATUS</th>\n",
       "      <th>DSM_IV_TR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>50002</td>\n",
       "      <td>1</td>\n",
       "      <td>Ambi</td>\n",
       "      <td>16.77</td>\n",
       "      <td>103.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>50003</td>\n",
       "      <td>1</td>\n",
       "      <td>R</td>\n",
       "      <td>24.45</td>\n",
       "      <td>124.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>50004</td>\n",
       "      <td>1</td>\n",
       "      <td>R</td>\n",
       "      <td>19.09</td>\n",
       "      <td>113.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>50005</td>\n",
       "      <td>2</td>\n",
       "      <td>R</td>\n",
       "      <td>13.73</td>\n",
       "      <td>119.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>50006</td>\n",
       "      <td>1</td>\n",
       "      <td>L</td>\n",
       "      <td>13.37</td>\n",
       "      <td>109.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>50007</td>\n",
       "      <td>1</td>\n",
       "      <td>R</td>\n",
       "      <td>17.78</td>\n",
       "      <td>110.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>50008</td>\n",
       "      <td>1</td>\n",
       "      <td>R</td>\n",
       "      <td>32.45</td>\n",
       "      <td>123.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>50009</td>\n",
       "      <td>1</td>\n",
       "      <td>R</td>\n",
       "      <td>33.86</td>\n",
       "      <td>126.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>50010</td>\n",
       "      <td>1</td>\n",
       "      <td>L</td>\n",
       "      <td>35.20</td>\n",
       "      <td>81.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>11.062651</td>\n",
       "      <td>19.767196</td>\n",
       "      <td>15.791557</td>\n",
       "      <td>6.084656</td>\n",
       "      <td>3.218855</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>50011</td>\n",
       "      <td>1</td>\n",
       "      <td>L</td>\n",
       "      <td>16.93</td>\n",
       "      <td>111.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SUB_ID  SEX HANDEDNESS_CATEGORY  AGE_AT_SCAN    FIQ    VIQ    PIQ  \\\n",
       "0   50002    1                Ambi        16.77  103.0  116.0   89.0   \n",
       "1   50003    1                   R        24.45  124.0  128.0  115.0   \n",
       "2   50004    1                   R        19.09  113.0  108.0  117.0   \n",
       "3   50005    2                   R        13.73  119.0  117.0  118.0   \n",
       "4   50006    1                   L        13.37  109.0   99.0  119.0   \n",
       "5   50007    1                   R        17.78  110.0  106.0  112.0   \n",
       "6   50008    1                   R        32.45  123.0  123.0  114.0   \n",
       "7   50009    1                   R        33.86  126.0  118.0  128.0   \n",
       "8   50010    1                   L        35.20   81.0   81.0   93.0   \n",
       "9   50011    1                   L        16.93  111.0  101.0  120.0   \n",
       "\n",
       "   ADOS_TOTAL  ADI_R_SOCIAL_TOTAL_A  ADI_R_VERBAL_TOTAL_BV  ADI_RRB_TOTAL_C  \\\n",
       "0   12.000000             16.000000               9.000000         5.000000   \n",
       "1   13.000000             27.000000              22.000000         5.000000   \n",
       "2   18.000000             19.000000              12.000000         5.000000   \n",
       "3   12.000000             23.000000              19.000000         3.000000   \n",
       "4   12.000000             13.000000              10.000000         4.000000   \n",
       "5   17.000000             21.000000              14.000000         9.000000   \n",
       "6   16.000000             24.000000              20.000000        10.000000   \n",
       "7   10.000000             20.000000              11.000000         3.000000   \n",
       "8   11.062651             19.767196              15.791557         6.084656   \n",
       "9   13.000000             24.000000              14.000000         6.000000   \n",
       "\n",
       "   ADI_R_ONSET_TOTAL_D  SUB_IN_SMP  CURRENT_MED_STATUS  DSM_IV_TR  \n",
       "0             4.000000           1                 0.0        1.0  \n",
       "1             3.000000           1                 1.0        1.0  \n",
       "2             3.000000           1                 0.0        1.0  \n",
       "3             4.000000           0                 1.0        1.0  \n",
       "4             3.000000           1                 0.0        1.0  \n",
       "5             1.000000           1                 0.0        1.0  \n",
       "6             2.000000           1                 1.0        1.0  \n",
       "7             2.000000           1                 1.0        1.0  \n",
       "8             3.218855           1                 0.0        1.0  \n",
       "9             1.000000           0                 0.0        1.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The handedness field contains categorical data, since it has considerably large number of missing values, NaN's are replaced by string 'n/a' (not available) as a new category \n",
    "my_dataset.HANDEDNESS_CATEGORY = my_dataset.HANDEDNESS_CATEGORY.fillna('n/a')\n",
    "        \n",
    "# Replacing other missing values with mean of respective columns\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "my_dataset.iloc[:, 3:12] = imputer.fit_transform(my_dataset.iloc[:, 3:12])\n",
    "        \n",
    "# Dropping all rows which still contain any NaN values\n",
    "my_dataset = my_dataset.dropna()\n",
    "my_dataset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0    427\n",
      "1.0    252\n",
      "2.0     85\n",
      "3.0     21\n",
      "Name: DSM_IV_TR, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(my_dataset['DSM_IV_TR'].value_counts())\n",
    "\n",
    "# Features in X and resultant classes in y\n",
    "X = np.array(my_dataset.iloc[:,1:14].values)\n",
    "y = np.array(my_dataset.iloc[:,14].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    The  DSM_IV_TR  field contains the resultant classes for Autism prediction labelled as:\n",
    "\n",
    "    0 - Control group\n",
    "    1 - Autism\n",
    "    2 - Aspergers\n",
    "    3 - PDD NOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot-encoding categorical data of HANDEDNESS_CATEGORY\n",
    "columnTransformer = ColumnTransformer([('encoder', OneHotEncoder(), [1])], remainder='passthrough')\n",
    "X = columnTransformer.fit_transform(X)\n",
    "\n",
    "# Feature Scaling\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)\n",
    "\n",
    "# Splitting the dataset into the Training set and Test set in ratio 80:20\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation and predicting classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating seven different models for multiclass classification and recording their accuracies as well as AUC_ROC score for comparing performance. Since ROC uses binary classes, a function is defined which binarizes the labels of predicted and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = ['Random Forest', 'Logistic Regression', 'kNN', 'SVM_rbf', 'ANN', 'XGBoost']\n",
    "accuracies = [0]*6\n",
    "auc_roc = [0]*6\n",
    "\n",
    "def multiclass_roc_auc_score(y_test, y_pred, average=\"macro\"):\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(y_test)\n",
    "    y_test = lb.transform(y_test)\n",
    "    y_pred = lb.transform(y_pred)\n",
    "    return roc_auc_score(y_test, y_pred, average=average)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest classifier**:\n",
    "\n",
    "A random forest is a meta estimator that fits a number of decision tree classifiers on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting. The parameters for the random forest training are defined as follows:\n",
    "\n",
    "*n_estimators*: This is the number of trees in the random forest classification. This model uses 45 trees decided after evaluation of a range of values.\n",
    "*min_samples_split*: This is the minimum number of samples required to split an internal node. The optimal value for the given  model was found to be 3.\n",
    "*max_depth*: The maximum depth of the tree, optimal value chosen is 15 here.\n",
    "\n",
    "\n",
    "The sub-sample size is always the same as the original input sample size but the samples are drawn with replacement if *bootstrap=True* (default)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Using the best parameters combination after tuning hyper-parameters\n",
    "rf_classifier = RandomForestClassifier(n_estimators = 45, min_samples_split = 3, max_depth = 15, \n",
    "                                       bootstrap = False, random_state = 42)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "accuracies[0] = accuracy_score(y_test, y_pred)\n",
    "auc_roc[0] = multiclass_roc_auc_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression classification**:\n",
    "\n",
    "In the multiclass case, this training algorithm uses the one-vs-rest (OvR) scheme if the ‘multi_class’ option is set to ‘ovr’. *solver* is the algorithm to use in the optimization problem. Maximum number of iterations taken for the solvers to converge are chosen to be 500. It is to be noted that the features (X) are already normalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(solver = 'saga', multi_class = 'ovr', max_iter = 500)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracies[1] = accuracy_score(y_test, y_pred)\n",
    "auc_roc[1] = multiclass_roc_auc_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**K-Nearest Neighbors**:\n",
    "\n",
    "KNN is a simple supervised classification algorithm we can use to assign a class to new data point. Larger K value leads to smoother decision boundary (less complex model). Smaller K leads to more complex model (may lead to overfitting). Testing accuracy penalizes models that are too complex(over fitting) or not complex enough(underfit). We're using an optimal value of k=5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "knn = KNeighborsClassifier(n_neighbors = 5, weights = 'distance')\n",
    "knn.fit(X_train, y_train) \n",
    "y_pred = knn.predict(X_test)  \n",
    "\n",
    "accuracies[2] = accuracy_score(y_test, y_pred)\n",
    "auc_roc[2] = multiclass_roc_auc_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Support Vector Machine**:\n",
    "\n",
    "Radial Basis Function (RBF) kernel is applied on the c-support vector classifier. Intuitively, the gamma parameter defines how far the influence of a single training example reaches, with low values meaning ‘far’ and high values meaning ‘close’. The gamma parameters can be seen as the inverse of the radius of influence of samples selected by the model as support vectors.\n",
    "\n",
    "The C parameter trades off correct classification of training examples against maximization of the decision function’s (One vs All) margin. For larger values of C, a smaller margin will be accepted if the decision function is better at classifying all training points correctly. A lower C will encourage a larger margin, therefore a simpler decision function, at the cost of training accuracy. In other words C behaves as a regularization parameter in the SVM. It is set to the value 0.8 as it gave better scores than default value of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC \n",
    "svm_model = SVC(kernel = 'rbf', gamma = 'auto', C=0.8)\n",
    "svm_model.fit(X_train, y_train) \n",
    "y_pred = svm_model.predict(X_test) \n",
    "\n",
    "accuracies[3] = accuracy_score(y_test, y_pred)\n",
    "auc_roc[3] = multiclass_roc_auc_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Artificial Neural Network**:\n",
    "\n",
    "In multi-class classification, the neural network has the same number of output nodes as the number of classes. Each output node belongs to a specific class and outputs a score for that class. Scores from the last layer are passed through a softmax layer. Softmax layer converts the score into probability values. At last, data is classified into a corresponding class, that has the highest probability value. The following ANN has 3 hidden layers and with dropout/regularization rate = 0.1\n",
    "\n",
    "The classifier is built on 'adam' optimizer and categorical cross-entropy for multiclass. Adam is a replacement optimization algorithm for stochastic gradient descent for training deep learning models. The data is cross validated using k-fold (k=10) on shuffled dataset. The ten accuracies are acquired from cross_val_score and their mean is recorded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "def build_classifier():\n",
    "    classifier = Sequential()\n",
    "    # Adding the input layer and the first hidden layer \n",
    "    classifier.add(Dense(units = 15, activation = 'relu', input_dim = 17))\n",
    "    # Adding a hidden layer\n",
    "    classifier.add(Dense(units = 7, activation = 'relu'))\n",
    "    classifier.add(Dropout(rate = 0.1))\n",
    "    # Adding a hidden layer\n",
    "    classifier.add(Dense(units = 9, activation = 'relu'))\n",
    "    classifier.add(Dropout(rate = 0.1))\n",
    "    # Adding a hidden layer\n",
    "    classifier.add(Dense(units = 7, activation = 'relu'))\n",
    "    classifier.add(Dropout(rate = 0.1))\n",
    "    # Adding the output layer\n",
    "    classifier.add(Dense(units = 4, activation = 'softmax'))\n",
    "    # Compiling the ANN\n",
    "    classifier.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return classifier\n",
    "\n",
    "# Encoding the classes in y\n",
    "y_binary = to_categorical(y)\n",
    "\n",
    "cv = KFold(n_splits=10, random_state=42, shuffle=True)\n",
    "classifier = KerasClassifier(build_fn = build_classifier, batch_size=25, epochs=200)\n",
    "acc_cv = cross_val_score(estimator = classifier, X = X, y = y_binary, cv = cv)\n",
    "\n",
    "accuracies[4] = acc_cv.mean()\n",
    "auc_roc[4] = ' '"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**XGBoost Classifier**:\n",
    "\n",
    "XGBoost (eXtreme Gradient Boosting) is an advanced implementation of gradient boosting algorithm. It's a powerful machine learning algorithm especially where speed and accuracy are concerned. This model requires parameter tuning to improve and fully leverage its advantages over other algorithms. Following parameters were taken into consideration from XGBoost documentation:\n",
    "\n",
    "    max_depth: Maximum depth of a tree. Increasing this value will make the model more complex and more likely to overfit.\n",
    "    objective: multi:softmax: set XGBoost to do multiclass classification, also need to set num_class(number of classes)\n",
    "    subsample: corresponds to the fraction of observations (the rows) to subsample at each step. \n",
    "    eta: learning_rate or step size shrinkage used in update to prevents overfitting. After each boosting step, we can directly get the weights of new features, and eta shrinks the feature weights to make the boosting process more conservative. \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASSIFICATION REPORT for XGBoost classifier... \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.99      0.95        87\n",
      "         1.0       0.80      0.85      0.82        46\n",
      "         2.0       0.62      0.40      0.48        20\n",
      "         3.0       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.85       157\n",
      "   macro avg       0.58      0.56      0.56       157\n",
      "weighted avg       0.81      0.85      0.83       157\n",
      "\n",
      "\n",
      "CONFUSION MATRIX for XGBoost classifier... \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\welcome\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[86,  0,  1,  0],\n",
       "       [ 4, 39,  3,  0],\n",
       "       [ 4,  8,  8,  0],\n",
       "       [ 1,  2,  1,  0]], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Create a classifier using best params\n",
    "xgb = XGBClassifier(booster='gbtree', objective='multi:softmax', max_depth = 11, n_estimators = 35,\n",
    "                    eta = 0.1, subsample  = 0.7, num_class = 4, random_state=42)\n",
    "# Fit the classifier with the training data\n",
    "xgb.fit(X_train,y_train)\n",
    "# Use trained model to predict output of test dataset\n",
    "y_pred = xgb.predict(X_test)\n",
    "\n",
    "accuracies[5] = accuracy_score(y_test, y_pred)\n",
    "auc_roc[5] = multiclass_roc_auc_score(y_test, y_pred)\n",
    "\n",
    "print('CLASSIFICATION REPORT for XGBoost classifier... \\n')\n",
    "print(classification_report(y_test,y_pred))\n",
    "print('\\nCONFUSION MATRIX for XGBoost classifier... \\n')\n",
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results \n",
    "\n",
    "In summary, the following six machine learning models were developed to classify Autism using 13 selected features from the ABIDE dataset and reducing the subjects to 785. Highest accuracy (84.71 %) and ROC_AUC score (0.74) was achieved by XGBoost algorithm, followed by Random Forest which too was pretty close. The classification report and confusion matrix of the best model is given above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifiers</th>\n",
       "      <th>Accuracy score</th>\n",
       "      <th>AUC-ROC Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.840764</td>\n",
       "      <td>0.735244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.668790</td>\n",
       "      <td>0.599839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>kNN</td>\n",
       "      <td>0.687898</td>\n",
       "      <td>0.619831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>SVM_rbf</td>\n",
       "      <td>0.796178</td>\n",
       "      <td>0.694598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ANN</td>\n",
       "      <td>0.819117</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.847134</td>\n",
       "      <td>0.747647</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Classifiers  Accuracy score AUC-ROC Score\n",
       "0        Random Forest        0.840764      0.735244\n",
       "1  Logistic Regression        0.668790      0.599839\n",
       "2                  kNN        0.687898      0.619831\n",
       "3              SVM_rbf        0.796178      0.694598\n",
       "4                  ANN        0.819117              \n",
       "5              XGBoost        0.847134      0.747647"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = {'Classifiers': model_name, 'Accuracy score': accuracies, 'AUC-ROC Score': auc_roc}\n",
    "models_df = pd.DataFrame(models, columns = ['Classifiers', 'Accuracy score', 'AUC-ROC Score'] )\n",
    "models_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
